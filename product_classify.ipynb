{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-01-14T02:27:40.599822Z",
     "iopub.status.busy": "2023-01-14T02:27:40.599620Z",
     "iopub.status.idle": "2023-01-14T02:27:40.603368Z",
     "shell.execute_reply": "2023-01-14T02:27:40.602848Z"
    },
    "id": "ioaprt5q5US7"
   },
   "source": [
    "Copyright 2023 Aaryan Chandna\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use an RNN model for this task since RNNs work well with sequential data, and I was processing sentences to try and predict the binary output. Vectorizing the words was important for the first layer of the model, as it would allow for the network to make use of the relations between words directly. As for the embedding dimension, I chose 16 since this was a smaller dataset and as such, a smaller embedding dimension would be more efficient. I also set batch size to 1 for a similar reason. For the RNN, I used 20 epochs for the first layer, and 10 for the second since this would make the model accurate while preventing overfitting. I found that it was consistently producing an output of around 70% accuracy on test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:27:40.612741Z",
     "iopub.status.busy": "2023-01-14T02:27:40.612545Z",
     "iopub.status.idle": "2023-01-14T02:27:42.890121Z",
     "shell.execute_reply": "2023-01-14T02:27:42.889360Z"
    },
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:04.101940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('trainingsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"trainingsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Length</th>\n",
       "      <th>Ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The benefits I think we will see from the chan...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would just add one more thing. While we shou...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ken, I don't have that number at my fingertips...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think the only part of the segment that I di...</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, nothing has changed. I have been an invest...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Content_Length  Ans\n",
       "0  The benefits I think we will see from the chan...              55    0\n",
       "1  I would just add one more thing. While we shou...              64    0\n",
       "2  Ken, I don't have that number at my fingertips...              51    0\n",
       "3  I think the only part of the segment that I di...             137    1\n",
       "4  No, nothing has changed. I have been an invest...              75    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ans']=df['product_related'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "df = df.drop('product_related', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Content_Length', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 2)\n"
     ]
    }
   ],
   "source": [
    "#splitting data into 3 sets: train and validation for creating model, and test for unbiased examination of model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainer, test = train_test_split(df, test_size=0.25)\n",
    "train, val = train_test_split(trainer, test_size=0.15)\n",
    "print(trainer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting pandas dfs to tensorflow\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train['Content'].values, train['Ans'].values))\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val['Content'].values, val['Ans'].values))\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((test['Content'].values, test['Ans'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling data into batches of size 1\n",
    "train_dataset=train_dataset.shuffle(10000).batch(1)\n",
    "val_dataset = val_dataset.shuffle(10000).batch(1)\n",
    "test_dataset=test_dataset.shuffle(10000).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:05.457879Z",
     "iopub.status.busy": "2023-01-14T02:28:05.457381Z",
     "iopub.status.idle": "2023-01-14T02:28:05.461589Z",
     "shell.execute_reply": "2023-01-14T02:28:05.460716Z"
    },
    "id": "SDRI_s_tX1Hk"
   },
   "outputs": [],
   "source": [
    "#cleaning input strings\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:05.465134Z",
     "iopub.status.busy": "2023-01-14T02:28:05.464692Z",
     "iopub.status.idle": "2023-01-14T02:28:05.477124Z",
     "shell.execute_reply": "2023-01-14T02:28:05.476443Z"
    },
    "id": "-c76RvSzsMnX"
   },
   "outputs": [],
   "source": [
    "#creating word vectorization layer\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:05.480591Z",
     "iopub.status.busy": "2023-01-14T02:28:05.480116Z",
     "iopub.status.idle": "2023-01-14T02:28:07.658124Z",
     "shell.execute_reply": "2023-01-14T02:28:07.657335Z"
    },
    "id": "GH4_2ZGJsa_X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:08.686934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [191]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-04 02:24:08.687341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [191]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = train_dataset.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.662874Z",
     "iopub.status.busy": "2023-01-14T02:28:07.662270Z",
     "iopub.status.idle": "2023-01-14T02:28:07.666069Z",
     "shell.execute_reply": "2023-01-14T02:28:07.665438Z"
    },
    "id": "SCIg_T50wOCU"
   },
   "outputs": [],
   "source": [
    "#vectorizing text method\n",
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.775349Z",
     "iopub.status.busy": "2023-01-14T02:28:07.774960Z",
     "iopub.status.idle": "2023-01-14T02:28:07.899944Z",
     "shell.execute_reply": "2023-01-14T02:28:07.899264Z"
    },
    "id": "2zhmpeViI1iG"
   },
   "outputs": [],
   "source": [
    "#vectorizing dataset strings\n",
    "train_ds = train_dataset.map(vectorize_text)\n",
    "val_ds = val_dataset.map(vectorize_text)\n",
    "test_ds = test_dataset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.903275Z",
     "iopub.status.busy": "2023-01-14T02:28:07.903058Z",
     "iopub.status.idle": "2023-01-14T02:28:07.910179Z",
     "shell.execute_reply": "2023-01-14T02:28:07.909503Z"
    },
    "id": "wMcs_H7izm5m"
   },
   "outputs": [],
   "source": [
    "#tuning data\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.913519Z",
     "iopub.status.busy": "2023-01-14T02:28:07.913066Z",
     "iopub.status.idle": "2023-01-14T02:28:07.915832Z",
     "shell.execute_reply": "2023-01-14T02:28:07.915306Z"
    },
    "id": "dkQP6in8yUBR"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.918933Z",
     "iopub.status.busy": "2023-01-14T02:28:07.918459Z",
     "iopub.status.idle": "2023-01-14T02:28:07.972921Z",
     "shell.execute_reply": "2023-01-14T02:28:07.972358Z"
    },
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          160016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating model\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.980702Z",
     "iopub.status.busy": "2023-01-14T02:28:07.980305Z",
     "iopub.status.idle": "2023-01-14T02:28:07.994007Z",
     "shell.execute_reply": "2023-01-14T02:28:07.993449Z"
    },
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:28:07.997110Z",
     "iopub.status.busy": "2023-01-14T02:28:07.996890Z",
     "iopub.status.idle": "2023-01-14T02:29:08.745685Z",
     "shell.execute_reply": "2023-01-14T02:29:08.744871Z"
    },
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:09.201453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_14' with dtype int64\n",
      "\t [[{{node Placeholder/_14}}]]\n",
      "2023-07-04 02:24:09.201880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype int64\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/191 [===========================>..] - ETA: 0s - loss: 0.6897 - binary_accuracy: 0.5889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:10.190844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [34]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-04 02:24:10.191279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype string\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 3ms/step - loss: 0.6902 - binary_accuracy: 0.5812 - val_loss: 0.6922 - val_binary_accuracy: 0.5294\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6836 - binary_accuracy: 0.5864 - val_loss: 0.6928 - val_binary_accuracy: 0.5294\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6758 - binary_accuracy: 0.5864 - val_loss: 0.6943 - val_binary_accuracy: 0.5294\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6686 - binary_accuracy: 0.5864 - val_loss: 0.6962 - val_binary_accuracy: 0.5294\n",
      "Epoch 5/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6619 - binary_accuracy: 0.5864 - val_loss: 0.6970 - val_binary_accuracy: 0.5294\n",
      "Epoch 6/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6557 - binary_accuracy: 0.5864 - val_loss: 0.6960 - val_binary_accuracy: 0.5294\n",
      "Epoch 7/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6492 - binary_accuracy: 0.5864 - val_loss: 0.6942 - val_binary_accuracy: 0.5294\n",
      "Epoch 8/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6393 - binary_accuracy: 0.5864 - val_loss: 0.6917 - val_binary_accuracy: 0.5294\n",
      "Epoch 9/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.5916 - val_loss: 0.6874 - val_binary_accuracy: 0.5294\n",
      "Epoch 10/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.6148 - binary_accuracy: 0.5969 - val_loss: 0.6829 - val_binary_accuracy: 0.5294\n",
      "Epoch 11/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5992 - binary_accuracy: 0.6021 - val_loss: 0.6785 - val_binary_accuracy: 0.5294\n",
      "Epoch 12/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5803 - binary_accuracy: 0.6545 - val_loss: 0.6737 - val_binary_accuracy: 0.5294\n",
      "Epoch 13/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5616 - binary_accuracy: 0.7016 - val_loss: 0.6665 - val_binary_accuracy: 0.5294\n",
      "Epoch 14/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5399 - binary_accuracy: 0.7801 - val_loss: 0.6614 - val_binary_accuracy: 0.5294\n",
      "Epoch 15/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5172 - binary_accuracy: 0.8377 - val_loss: 0.6566 - val_binary_accuracy: 0.5294\n",
      "Epoch 16/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.4965 - binary_accuracy: 0.8534 - val_loss: 0.6512 - val_binary_accuracy: 0.5294\n",
      "Epoch 17/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.4661 - binary_accuracy: 0.8953 - val_loss: 0.6427 - val_binary_accuracy: 0.5294\n",
      "Epoch 18/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.4416 - binary_accuracy: 0.9215 - val_loss: 0.6379 - val_binary_accuracy: 0.5294\n",
      "Epoch 19/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.4162 - binary_accuracy: 0.9529 - val_loss: 0.6301 - val_binary_accuracy: 0.6471\n",
      "Epoch 20/20\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.3899 - binary_accuracy: 0.9634 - val_loss: 0.6239 - val_binary_accuracy: 0.6765\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:29:08.749611Z",
     "iopub.status.busy": "2023-01-14T02:29:08.749051Z",
     "iopub.status.idle": "2023-01-14T02:29:10.304995Z",
     "shell.execute_reply": "2023-01-14T02:29:10.304256Z"
    },
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 729us/step - loss: 0.5830 - binary_accuracy: 0.6933\n",
      "Loss:  0.5829906463623047\n",
      "Accuracy:  0.6933333277702332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:16.917847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-04 02:24:16.918362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [75]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.3704 - binary_accuracy: 0.9843 - val_loss: 0.6194 - val_binary_accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.3427 - binary_accuracy: 0.9948 - val_loss: 0.6129 - val_binary_accuracy: 0.6471\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.3165 - binary_accuracy: 0.9948 - val_loss: 0.6095 - val_binary_accuracy: 0.6176\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.2923 - binary_accuracy: 0.9948 - val_loss: 0.6054 - val_binary_accuracy: 0.6176\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.2748 - binary_accuracy: 1.0000 - val_loss: 0.5991 - val_binary_accuracy: 0.6765\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.2565 - binary_accuracy: 1.0000 - val_loss: 0.5933 - val_binary_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.2323 - binary_accuracy: 1.0000 - val_loss: 0.5891 - val_binary_accuracy: 0.6471\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.2153 - binary_accuracy: 1.0000 - val_loss: 0.5879 - val_binary_accuracy: 0.6471\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1995 - binary_accuracy: 1.0000 - val_loss: 0.5838 - val_binary_accuracy: 0.6471\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1890 - binary_accuracy: 1.0000 - val_loss: 0.5852 - val_binary_accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "#2nd run of RNN\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 712us/step - loss: 0.5217 - binary_accuracy: 0.7467\n",
      "Loss:  0.5216538310050964\n",
      "Accuracy:  0.746666669845581\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:29:10.582364Z",
     "iopub.status.busy": "2023-01-14T02:29:10.582116Z",
     "iopub.status.idle": "2023-01-14T02:29:13.437348Z",
     "shell.execute_reply": "2023-01-14T02:29:13.436579Z"
    },
    "id": "FWXsMvryuZuq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 02:24:20.435636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [75]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-04 02:24:20.435934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [75]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 845us/step - loss: 0.5217 - accuracy: 0.7467\n",
      "0.746666669845581\n"
     ]
    }
   ],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "loss, accuracy = export_model.evaluate(test_dataset)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-14T02:29:13.440723Z",
     "iopub.status.busy": "2023-01-14T02:29:13.440195Z",
     "iopub.status.idle": "2023-01-14T02:29:13.612802Z",
     "shell.execute_reply": "2023-01-14T02:29:13.612083Z"
    },
    "id": "QW355HH5L49K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8452713]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [\"And it is so far. It just depends on -- what we're hearing from those clients is not that they're making cuts to their capital spending programs, but that they might if the country doesn't open back up or their respective states don't open up because their biggest consumers of gas are restaurants, bars, hotel services, hotels that have restaurants and bars and that type of industry. So if those demands stay down, they may not have the need. You're not seeing a lot of -- you're seeing drops in new housing and some of those -- so those customers, those new customers that they would have, there won't be that need there. So there'll be reductions there. As far as replacement or maintenance of existing systems or old systems, that work is going to continue.\"]\n",
    "export_model.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "  listText = [text]\n",
    "  if export_model.predict(listText) >= 0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"And it is so far. It just depends on -- what we're hearing from those clients is not that they're making cuts to their capital spending programs, but that they might if the country doesn't open back up or their respective states don't open up because their biggest consumers of gas are restaurants, bars, hotel services, hotels that have restaurants and bars and that type of industry. So if those demands stay down, they may not have the need. You're not seeing a lot of -- you're seeing drops in new housing and some of those -- so those customers, those new customers that they would have, there won't be that need there. So there'll be reductions there. As far as replacement or maintenance of existing systems or old systems, that work is going to continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
